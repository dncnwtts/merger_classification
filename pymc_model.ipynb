{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "from scipy.special import logsumexp\n",
    "import pymc3 as pm\n",
    "import theano.tensor as TT\n",
    "import accuracy_analysis as aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample(N, f_M, r_Ms, r_Is, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    true_gals = np.random.choice([0,1], size=N, p=[1-f_M, f_M])\n",
    "    f_M_sample = true_gals.sum()/N\n",
    "    N_true = true_gals.sum()\n",
    "    \n",
    "    n = len(r_Ms)\n",
    "    \n",
    "\n",
    "    # Matrix of classifier answers\n",
    "    m = np.zeros((n, N), dtype='int')\n",
    "    for i in range(n):\n",
    "        for j in range(N):\n",
    "            if true_gals[j] == 0:\n",
    "                m[i,j] = np.random.choice([0,1], p=[r_Is[i], 1-r_Is[i]])\n",
    "            elif true_gals[j] == 1:\n",
    "                m[i,j] = np.random.choice([0,1], p=[1-r_Ms[i], r_Ms[i]])\n",
    "\n",
    "    \n",
    "    return N_true, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_M_true = 0.2\n",
    "f_M_train = 0.5\n",
    "\n",
    "cfer_probs = np.asarray([[0.9, 0.7],\n",
    "                         [0.7, 0.9],\n",
    "                         [0.8, 0.8],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.8, 0.8],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.8, 0.8],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.8, 0.8],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.7, 0.7],\n",
    "                         [0.9, 0.9]])\n",
    "\n",
    "n_cfers = len(cfer_probs)\n",
    "\n",
    "r_Is = cfer_probs[:, 0]\n",
    "r_Ms = cfer_probs[:, 1]\n",
    "\n",
    "n_obj = 200\n",
    "true, obs = make_sample(n_obj, f_M_true, r_Ms, r_Is, seed=1234)\n",
    "\n",
    "n_train = 20\n",
    "true_train, obs_train = make_sample(n_train, f_M_train, r_Ms, r_Is, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flat(observations):\n",
    "    n_cfers, n_obj = observations.shape\n",
    "    obs_flat = observations.ravel()\n",
    "    \n",
    "    cfer_ids = np.zeros([n_cfers, n_obj], dtype='int')\n",
    "    for i in range(n_cfers):\n",
    "        cfer_ids[i] = i\n",
    "    cfer_ids = cfer_ids.ravel()\n",
    "    \n",
    "    obj_ids = np.zeros([n_cfers, n_obj], dtype='int')\n",
    "    for j in range(n_obj):\n",
    "        obj_ids[:, j] = j\n",
    "    obj_ids = obj_ids.ravel()\n",
    "    \n",
    "    return obs_flat, obj_ids, cfer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_pars(truths, observed):\n",
    "    t0 = (truths==0)\n",
    "    t1 = (truths==1)\n",
    "    o0 = (observed==0)\n",
    "    o1 = (observed==1)\n",
    "    \n",
    "    a_00 = np.count_nonzero(t0 & o0, axis=1) + 1\n",
    "    b_00 = np.count_nonzero(t0 & o1, axis=1) + 1\n",
    "    b_11 = np.count_nonzero(t1 & o0, axis=1) + 1\n",
    "    a_11 = np.count_nonzero(t1 & o1, axis=1) + 1\n",
    "    \n",
    "    return a_00, b_00, a_11, b_11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chains(obs, obs_train, true_train):\n",
    "    '''\n",
    "    these arrays are n_galaxies x n_classifiers, and are 0 for isolated, 1 for merger.\n",
    "    '''\n",
    "    obs_classes, obj_ids, cfer_ids = make_flat(obs)\n",
    "    a_00, b_00, a_11, b_11 = get_beta_pars(true_train, obs_train) \n",
    "\n",
    "    \n",
    "    with pm.Model() as explicit_model:\n",
    "        f_M = pm.Uniform('fM', 0, 1)\n",
    "        r_Is = pm.Beta('rI', alpha=a_00, beta=b_00, shape=n_cfers)\n",
    "        r_Ms = pm.Beta('rM', alpha=a_11, beta=b_11, shape=n_cfers)\n",
    "    \n",
    "        #the \"real\" data\n",
    "        true_class = pm.Bernoulli('true_class', f_M, shape=n_obj)\n",
    "        N_M_true = pm.Deterministic('N_M', TT.sum(true_class))\n",
    "        p_obs_1 = TT.switch(TT.eq(true_class[obj_ids], 1), r_Ms[cfer_ids], 1-r_Is[cfer_ids])\n",
    "        observed = pm.Bernoulli('observed', p_obs_1, observed=obs_classes)\n",
    "\n",
    "    with explicit_model:\n",
    "        trace = pm.sample(draws=5000)\n",
    "\n",
    "    return trace.get_values('fM'), trace.get_values('rI'), trace.get_values('rM'), trace.get_values('true_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">NUTS: [rM, rI, fM]\n",
      ">BinaryGibbsMetropolis: [true_class]\n",
      "Sampling 4 chains, 0 divergences: 100%|██████████| 22000/22000 [03:23<00:00, 108.20draws/s]\n"
     ]
    }
   ],
   "source": [
    "f_Ms, r_Is, r_Ms, classif = get_chains(obs, obs_train, true_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(f_Ms, 51)\n",
    "plt.xlabel(r'$f_M$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "p\\left(G_{k} \\mid\\left\\{m_{i j}, r_{i j k}\\right\\}\\right)=& \\frac{p\\left(\\left\\{m_{i j}\\right\\} \\mid G_{k},\\left\\{r_{i j k}\\right\\}\\right) p\\left(G_{k}\\right)}{\\sum_{k^{\\prime}} p\\left(\\left\\{m_{i j}\\right\\} \\mid G_{k^{\\prime}},\\left\\{r_{i j k^{\\prime}}\\right\\}\\right) p\\left(G_{k^{\\prime}}\\right)} \\\\\n",
    "&=\\frac{\\prod_{i} p\\left(m_{i j} \\mid G_{k}, r_{i j k}\\right) p\\left(G_{k}\\right)}{\\sum_{k^{\\prime}} \\prod_{i} p\\left(m_{i j} \\mid G_{k^{\\prime}}, r_{i j k^{\\prime}}\\right) p\\left(G_{k^{\\prime}}\\right)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_Ms = np.zeros((1000, n_obj))\n",
    "for k in range(len(p_Ms)):\n",
    "    for j in range(n_obj):\n",
    "        num = 1\n",
    "        den_I = 1\n",
    "        den_M = 1\n",
    "        for i in range(n_cfers):\n",
    "            if obs[i,j] == 0:\n",
    "                num *= (1-r_Ms[k,i])\n",
    "                den_M *= (1-r_Ms[k,i])\n",
    "                den_I *= r_Is[k,i]\n",
    "            else:\n",
    "                num *= r_Ms[k,i]\n",
    "                den_M *= r_Ms[k,i]\n",
    "                den_I *= (1-r_Ms[k,i])\n",
    "        p_Ms[k,j] = num*f_Ms[k]/(den_M*f_Ms[k]+den_I*(1-f_Ms[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yll, mu, yul = np.percentile(p_Ms, [16,50,68], axis=0)\n",
    "plt.errorbar(np.arange(200), mu, yerr=[mu-yll, yul-mu], fmt='.')\n",
    "plt.xlabel('Galaxy index')\n",
    "plt.ylabel(r'$p_M$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3-anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
